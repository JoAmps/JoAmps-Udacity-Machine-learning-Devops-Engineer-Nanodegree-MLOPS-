# Udacity MLOPS nanodegree
![Logo](https://upload.wikimedia.org/wikipedia/commons/3/3b/Udacity_logo.png)
### This repo contains the various projects performed to attain the udacity MLOPS nanodegree.I developed skills that were crucial, by going through 4 key courses in MLOPS. There were 4 projects completed under each course, and my solutions to the projects can be found in the folders here. MLOPS is a crucial skill that data scientists and machine learning engineers need to have , because most often, they train the models and leave it in a jupyter notebook serving no purpose, but these models need to be shipped to production to solve real world issues. Its also important for professionals to write clean, modular and efficient production ready code, train models deploy them into production environments, and monitor their performance over time, nd retrain them, when the model starts degrading. All these are things i learnt in this course, which would help me greatly in my career. Below is just a summary of the courses taught:
### Clean Code Principles:
#### I Developed skills that are essential for deploying production machine learning models. Firstly, i learnt coding best practices on auto-pilot by learning how to use PyLint and AutoPEP8. Then i will expanded my git and Github skills to work with teams. Finally, i learnt best practices associated with testing and logging used in production settings in order to ensure my models can stand the test of time.
### Building a Reproducible Model Workflow:
#### This course empowered me to be more efficient, effective, and productive in modern, real-world ML projects by adopting best practices around reproducible workflows. In particular, it taught me the fundamentals of MLops and how to: a) create a clean, organized, reproducible, end-to-end machine learning pipeline from scratch using MLflow b) clean and validate the data using pytest c) track experiments, code, and results using GitHub and Weights & Biases d) select the best-performing model for production and e) deploy a model using MLflow. Along the way, it touched on other technologies like Kubernetes, Kubeflow, and Great Expectations, which further peaked my interest to learn them also
### Deploying a Scalable ML Pipeline in Production:
#### This course taught me how to robustly deploy a machine learning model into production. En route to that goal, i learnt how to put the finishing touches on a model by taking a fine grained approach to model performance, checking bias, and ultimately writing a model card. I also learned how to version control my data and models using Data Version Control (DVC). The last piece in preparation for deployment was learning Continuous Integration and Continuous Deployment which was accomplished using GitHub Actions and Heroku, respectively. Finally, I learnt how to write a fast, type-checked, and auto-documented API using FastAPI.
### Automated model scoring and monitoring:
#### This course taught me how to automate the devops processes required to score and re-deploy my ML models. I learnt how to automate model training and deployment. I was taught how to set up regular scoring processes to be performed after model deployment, and also learnt to reason carefully about model drift, and whether models need to be retrained and re-deployed. I learnt to diagnose operational issues with models, including data integrity and stability problems, timing problems, and dependency issues. Finally, I learnt to set up automated reporting with APIâ€™s.

## Authors

- [@JoAmps](https://www.github.com/JoAmps)


